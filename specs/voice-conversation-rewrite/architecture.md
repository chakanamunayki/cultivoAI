# Voice Conversation Architecture

## System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Browser (Client)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  voice-conversation-mode.tsx (UI Component)                   â”‚  â”‚
â”‚  â”‚  - Brutalist design (borders, shadows, animations)            â”‚  â”‚
â”‚  â”‚  - Recording button, status indicators                        â”‚  â”‚
â”‚  â”‚  - Transcription display                                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                   â”‚                                                  â”‚
â”‚                   â–¼                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  use-gemini-live.ts (Hook)                                    â”‚  â”‚
â”‚  â”‚  - Session management (@google/genai SDK)                     â”‚  â”‚
â”‚  â”‚  - Audio input/output coordination                            â”‚  â”‚
â”‚  â”‚  - State management (recording, speaking, errors)             â”‚  â”‚
â”‚  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜  â”‚
â”‚      â”‚                                                       â”‚      â”‚
â”‚      â–¼                                                       â–¼      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Audio Input Pipeline       â”‚     â”‚  Audio Output Pipeline   â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚  1. Microphone (getUserMedia)â”‚    â”‚  1. Receive PCM (24kHz)  â”‚ â”‚
â”‚  â”‚  2. AudioContext (16kHz)     â”‚    â”‚  2. Decode base64        â”‚ â”‚
â”‚  â”‚  3. Audio Worklet Processor  â”‚    â”‚  3. Create AudioBuffer   â”‚ â”‚
â”‚  â”‚  4. Float32 â†’ PCM16 convert  â”‚    â”‚  4. Play via Web Audio   â”‚ â”‚
â”‚  â”‚  5. Base64 encode            â”‚    â”‚                          â”‚ â”‚
â”‚  â”‚  6. Send to Gemini SDK       â”‚    â”‚                          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                â”‚                                                    â”‚
â”‚                â–¼                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  @google/genai SDK                                            â”‚ â”‚
â”‚  â”‚  - WebSocket connection management                            â”‚ â”‚
â”‚  â”‚  - Protocol handling (BidiGenerateContent)                    â”‚ â”‚
â”‚  â”‚  - Audio streaming (sendRealtimeInput)                        â”‚ â”‚
â”‚  â”‚  - Response handling (onmessage callbacks)                    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                   â”‚                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”‚ HTTPS + WebSocket
                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   â–¼                   Next.js Backend               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  /api/voice/token (Token Generation)                         â”‚  â”‚
â”‚  â”‚  - Uses @google/generative-ai                                â”‚  â”‚
â”‚  â”‚  - Creates ephemeral token (1 use, 30min expiry)             â”‚  â”‚
â”‚  â”‚  - Constraints: model, voice, responseModalities             â”‚  â”‚
â”‚  â”‚  - Returns token string to client                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Database Logging (PostgreSQL + Drizzle)                     â”‚  â”‚
â”‚  â”‚  - Conversation metadata                                     â”‚  â”‚
â”‚  â”‚  - Transcriptions (user + AI)                                â”‚  â”‚
â”‚  â”‚  - Performance metrics (latency)                             â”‚  â”‚
â”‚  â”‚  - Error logs                                                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”‚ WebSocket (wss://)
                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   â–¼                 Google Gemini Live API          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  Model: gemini-2.5-flash-native-audio-preview-09-2025               â”‚
â”‚  API Version: v1alpha                                                â”‚
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Audio Processing Pipeline                                    â”‚  â”‚
â”‚  â”‚  1. Speech-to-Text (STT) - 16kHz PCM â†’ Text                  â”‚  â”‚
â”‚  â”‚  2. Language Model (LLM) - Generate response                 â”‚  â”‚
â”‚  â”‚  3. Text-to-Speech (TTS) - Text â†’ 24kHz PCM audio            â”‚  â”‚
â”‚  â”‚  4. Voice Activity Detection (VAD)                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                       â”‚
â”‚  Features:                                                           â”‚
â”‚  - Proactive audio (model decides when to speak)                    â”‚
â”‚  - Affective dialog (adapts tone to emotion)                        â”‚
â”‚  - 30+ voices in 24+ languages                                      â”‚
â”‚  - Session resumption (for long conversations)                      â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Authentication Flow

```
1. User clicks "Start Voice Conversation"
   â†“
2. Frontend: fetch('/api/voice/token')
   â†“
3. Backend: GoogleGenerativeAI.auth.createEphemeralToken({
     config: {
       uses: 1,
       expireTime: now + 30min,
       liveConnectConstraints: {
         model: "gemini-2.5-flash-native-audio-preview-09-2025",
         config: { responseModalities: ["AUDIO"], speechConfig: {...} }
       }
     }
   })
   â†“
4. Backend: Return { token: "..." }
   â†“
5. Frontend: Initialize SDK
   const ai = new GoogleGenAI({
     apiKey: token,
     httpOptions: { apiVersion: "v1alpha" }
   })
   â†“
6. Frontend: Connect to Live API
   const session = await ai.live.connect({
     model: "gemini-2.5-flash-native-audio-preview-09-2025",
     config: {...},
     callbacks: { onopen, onmessage, onerror, onclose }
   })
   â†“
7. Session established, ready for audio streaming
```

---

## Audio Streaming Flow

### User Speaks â†’ AI Hears

```
1. Microphone captures audio (browser sample rate, e.g., 48kHz)
   â†“
2. AudioContext resamples to 16kHz
   â†“
3. Audio Worklet Processor (pcm-processor.js):
   - Collects 20ms chunks (320 samples at 16kHz)
   - Converts Float32 â†’ Int16 PCM
   - Posts message with PCM buffer
   â†“
4. Hook receives PCM buffer:
   - Base64 encodes the buffer
   - Calls session.sendRealtimeInput({
       audio: { data: base64Audio, mimeType: "audio/pcm;rate=16000" }
     })
   â†“
5. SDK sends audio over WebSocket to Gemini
   â†“
6. Gemini VAD detects end of speech (300ms silence)
   â†“
7. Gemini STT converts audio â†’ text
   â†“
8. Gemini LLM generates response
   â†“
9. Gemini TTS converts response â†’ 24kHz PCM audio
   â†“
10. Audio streamed back to client
```

### AI Responds â†’ User Hears

```
1. SDK receives audio response in onmessage callback
   â†“
2. Extract audio data:
   message.serverContent.modelTurn.parts[{inlineData: {data: base64, mimeType}}]
   â†“
3. Decode base64 â†’ ArrayBuffer (PCM 24kHz)
   â†“
4. Create AudioBuffer:
   const audioBuffer = audioContext.createBuffer(1, samples, 24000)
   audioBuffer.getChannelData(0).set(pcmData)
   â†“
5. Create AudioBufferSourceNode:
   const source = audioContext.createBufferSource()
   source.buffer = audioBuffer
   source.connect(audioContext.destination)
   source.start()
   â†“
6. User hears AI response in real-time
```

---

## State Machine

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   IDLE      â”‚ â† Initial state
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ User clicks "Start"
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INITIALIZING   â”‚ â† Fetching token, setting up audio
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Session connected
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CONNECTED      â”‚ â† Ready for conversation
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ User clicks mic button
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RECORDING      â”‚ â† Capturing audio, sending to Gemini
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ VAD detects end of speech
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PROCESSING     â”‚ â† Waiting for AI response
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Audio response received
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SPEAKING       â”‚ â† AI audio playing
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Audio finishes
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CONNECTED      â”‚ â† Back to ready state
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ User clicks "Stop" or error occurs
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DISCONNECTED   â”‚ â† Session ended, cleanup complete
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ User clicks "Start" again
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INITIALIZING   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Error States

Any state can transition to:
- **ERROR** â†’ Display error message, show retry button
- **RECONNECTING** â†’ Temporary state while reconnecting after network interruption

---

## Key Files & Responsibilities

### Frontend

| File | Responsibility |
|------|----------------|
| `src/components/landing/voice-conversation-mode.tsx` | UI component (Brutalist design), user interactions |
| `src/hooks/use-gemini-live.ts` | Session management, audio coordination, state machine |
| `public/pcm-processor.js` | Audio Worklet for low-latency PCM conversion |

### Backend

| File | Responsibility |
|------|----------------|
| `src/app/api/voice/token/route.ts` | Ephemeral token generation |
| `src/lib/db.ts` | Database connection |
| `src/lib/schema.ts` | Conversation logging schema |

### Configuration

| File | Responsibility |
|------|----------------|
| `src/content/es.ts` | Spanish content (voice UI labels) |
| `src/content/en.ts` | English content (voice UI labels) |
| `.env.local` | `GEMINI_API_KEY` environment variable |

---

## Data Flow: One Complete Turn

```
User speaks "Â¿QuÃ© servicios ofrecen?" (in Spanish)
  â†“
Microphone â†’ AudioContext (16kHz) â†’ Audio Worklet
  â†“
Worklet: Float32 â†’ PCM16 â†’ base64
  â†“
Hook: sendRealtimeInput({ audio: { data: base64, mimeType: "audio/pcm;rate=16000" }})
  â†“
SDK â†’ WebSocket â†’ Gemini Live API
  â†“
Gemini VAD: Detects 300ms silence, end of speech
  â†“
Gemini STT: "Â¿QuÃ© servicios ofrecen?" (transcription)
  â†“
Gemini LLM: Generates response based on system prompt + conversation history
  â†“
Gemini TTS: Converts response to Spanish audio (Kore voice, 24kHz PCM)
  â†“
WebSocket â†’ SDK â†’ onmessage callback
  â†“
Hook: Decode base64 â†’ PCM â†’ AudioBuffer (24kHz)
  â†“
Web Audio API: Play audio
  â†“
User hears: "Ofrecemos consultorÃ­a en IA, automatizaciÃ³n, integraciÃ³n de APIs..."
  â†“
Database: Log turn (user transcription, AI transcription, audio URL, latency)
```

---

## Performance Targets

| Metric | Target | How to Measure |
|--------|--------|----------------|
| Token fetch latency | <200ms | `console.time('token-fetch')` |
| Connection establishment | <500ms | Time from `connect()` to `onopen` |
| Audio chunk latency | <50ms | Time from microphone â†’ `sendRealtimeInput()` |
| VAD trigger time | 300ms | Configured in `silenceDurationMs` |
| STT latency | <300ms | Time from VAD trigger â†’ transcription received |
| LLM latency | <500ms | Time from transcription â†’ response text |
| TTS latency (first byte) | <700ms | Time from response text â†’ first audio chunk |
| Audio playback latency | <100ms | Time from audio received â†’ speaker output |
| **Total round-trip** | **<1000ms** | User stops speaking â†’ AI starts speaking |

---

## Security Considerations

1. **Ephemeral Tokens**:
   - Never expose `GEMINI_API_KEY` to client
   - Tokens are single-use, 30-min expiry
   - Constrained to specific model and config

2. **Audio Privacy**:
   - Audio never stored on server (unless user explicitly saves)
   - Transcriptions logged to database (encrypted at rest)
   - User can delete conversation history

3. **Rate Limiting**:
   - Gemini Free Tier: 60 requests/min
   - Implement client-side rate limiting if needed

4. **Input Validation**:
   - Validate audio MIME type and sample rate
   - Limit audio chunk size to prevent abuse

---

## Browser Compatibility

| Browser | Support | Notes |
|---------|---------|-------|
| Chrome 90+ | âœ… Full | Primary target, Audio Worklet support |
| Firefox 88+ | âœ… Full | Requires same sample rate for recording + playback |
| Safari 14.1+ | âš ï¸ Partial | Audio Worklet support varies, test thoroughly |
| Edge 90+ | âœ… Full | Chromium-based, same as Chrome |

---

## Configuration Options

### Voice Selection (by locale)

```typescript
const VOICE_CONFIG = {
  es: { voiceName: "Kore" },  // Spanish
  en: { voiceName: "Kore" }   // English (or alternative)
};
```

### VAD Tuning

```typescript
const VAD_CONFIG = {
  automaticActivityDetection: {
    disabled: false,           // Let Gemini handle VAD
    prefixPaddingMs: 100,      // Capture speech onset
    silenceDurationMs: 300     // Adjust for responsiveness
  }
};

// Increase silenceDurationMs for:
// - Users who pause mid-sentence
// - Noisy environments

// Decrease silenceDurationMs for:
// - Faster, more responsive conversation
// - Users who speak in short bursts
```

### Session Resumption

```typescript
const SESSION_CONFIG = {
  sessionResumption: {}  // Enable resumption
};

// Listen for sessionResumptionUpdate in onmessage
// Store handle in localStorage
// Reconnect with: sessionResumption: { handle: storedHandle }
```

---

## Monitoring & Debugging

### Console Logs (Development)

```typescript
console.log('ğŸ¤ Recording started');
console.log('ğŸ”Š Sending audio chunk', { size: pcmData.byteLength });
console.log('ğŸ¤– AI response received', { transcription, audioLength });
console.log('â±ï¸ Latency:', { stt: 250, llm: 450, tts: 600, total: 1300 });
console.error('âŒ Error:', error.message);
```

### Database Metrics

Log to `conversations` table:
- Start time, end time, duration
- Turn count
- Average latency per turn
- Error count
- Voice used
- Locale

### Browser DevTools

- **Performance tab**: Profile audio processing, identify bottlenecks
- **Network tab**: Check WebSocket messages, verify chunk sizes
- **Memory tab**: Detect leaks (AudioContext, AudioBufferSource not cleaned up)

---

## Rollback Strategy

If SDK approach has critical issues:

1. **Do NOT revert to raw WebSockets** (known to fail)
2. Debug SDK issues:
   - Check SDK version (`pnpm list @google/genai`)
   - Review SDK GitHub issues
   - Test with minimal example from official docs
3. Contact Google support with:
   - SDK version
   - Error messages
   - Minimal reproduction code
4. Temporary workaround: Disable voice, use text-only chat
